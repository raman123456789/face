{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhoni\n",
      "SACHIN\n",
      "SHARUK\n",
      "RAHUL\n",
      "prabhas\n",
      "Barack_Obama_test\n",
      "modi\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "['SHARUK', 'Barack_Obama_test', 'prabhas']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "def encoding_finder(path):\n",
    "    face_enc = []\n",
    "    face_names=[]\n",
    "    path=os.getcwd()+path\n",
    "    for name in glob.glob(path): \n",
    "        image = face_recognition.load_image_file(name)\n",
    "        img_enc = face_recognition.face_encodings(image)[0]\n",
    "        face_enc.append(img_enc)\n",
    "        n=str(name)\n",
    "        n=name.split('/',-1)\n",
    "        n=n[-1].split('.',-1)\n",
    "        n=n[0]\n",
    "        face_names.append(n)\n",
    "        print(n)\n",
    "    return face_enc,face_names\n",
    "known_face_encodings ,known_face_names=encoding_finder('/KNOW_FACE_IMAGES/*')\n",
    "blur_images=['SHARUK','modi']\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "unique_faces=[]\n",
    "process_this_frame = True\n",
    "#video_capture = cv2.VideoCapture(0)\n",
    "video_capture = cv2.VideoCapture('multiple_faces.mp4')\n",
    "                      \n",
    "\n",
    "while process_this_frame:\n",
    "    ret, frame = video_capture.read()\n",
    "    process_this_frame=ret\n",
    "    framespersecond= int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('/home/raman/IRS/haarcascade_frontalface_default.xml')\n",
    "    face_1 = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    face_names = []\n",
    "    for (x, y, w, h) in face_1:\n",
    "        s_f=frame[y:y+h+100, x:x+w]\n",
    "        rgb_small_frame = s_f[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        name=\"unknown\"\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "    print(face_names)\n",
    "    for (x, y, w, h),name in zip(face_1,face_names):\n",
    "        if name in blur_images:\n",
    "            #sub_face=frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (x + 6, y+h- 6), font, 1.0, (255, 0, 0), 2)\n",
    "        else:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.rectangle(frame, (x, y+h- 35), (x+w, y+h), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (x + 6, y+h- 6), font, 1.0, (255, 0, 0), 2)\n",
    "            \n",
    "    cv2.putText(frame,str(framespersecond) , (50,50), font, 1.0, (255, 0, 0), 2)\n",
    "    cv2.imshow(\"face_blur_window\",frame)\n",
    "    \n",
    "    \n",
    "                                                  \n",
    "                                                  \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "video_capture.release()                                                 \n",
    "cv2.destroyAllWindows()\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
